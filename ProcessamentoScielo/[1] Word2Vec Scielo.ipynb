{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec** é um método para gerar *Word Embeddings* a partir de um corpus de texto, utilizando redes neurais.\n",
    "\n",
    "Desenvolvido por Tomas Mikolov *et al.* (Google) em 2013, é um dos métodos de geração de *word embeddings* mais populares em tarefas de processamento de linguagem natural (PLN) como análise de sentimento, tradução de textos e reconhecimento de entidades nomeadas (NER).\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Para exercitar, vamos treinar um modelo **Word2Vec** com o corpus da Scielo \n",
    "\n",
    "https://drive.google.com/file/d/1Hh_FWgKk7TGVp0cKgqy6Hw1vxylwowEQ/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 1 - importanto as bibliotecas\n",
    "Vamos primeiro instalar e importar as bibliotecas que utilizaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "import nltk\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import spacy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o pré-processamento em língua portuguesa, vamos usar o pacote ```pt_core_news_sm```. Instale antes com:\n",
    "    \n",
    "```python -m spacy download pt_core_news_sm```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 2 - Pré-processamento do *corpus*\n",
    "\n",
    "\n",
    "Vamos abrir o arquivo e transformá-lo em um *dataframe*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r\"corpus_scielo.txt\", \"r\", encoding='UTF-8')\n",
    "df = pd.DataFrame(file)\n",
    "df.columns = ['lines']\n",
    "df = df.sort_index()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim são os textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A avifauna da região de Vila Bela da Santíssim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Composição de bandos mistos de aves em fragmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morcegos do Estado do Paraná, Brasil (Mammalia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Riqueza da fauna de formigas (Hymenoptera: For...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lista de tipos de Dermaptera e Orthoptera (Ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729650</th>\n",
       "      <td>Antonio Austregésilo ou a grandeza e a dignida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729651</th>\n",
       "      <td>A 20.a enfermaria de Santa Casa em 1920.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729652</th>\n",
       "      <td>Antonio Austregésilo, o psiquiatra.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729653</th>\n",
       "      <td>As reações de Takata e formol-gel em face da p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729654</th>\n",
       "      <td>As reaç</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>729655 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    lines\n",
       "0       A avifauna da região de Vila Bela da Santíssim...\n",
       "1       Composição de bandos mistos de aves em fragmen...\n",
       "2       Morcegos do Estado do Paraná, Brasil (Mammalia...\n",
       "3       Riqueza da fauna de formigas (Hymenoptera: For...\n",
       "4       Lista de tipos de Dermaptera e Orthoptera (Ins...\n",
       "...                                                   ...\n",
       "729650  Antonio Austregésilo ou a grandeza e a dignida...\n",
       "729651         A 20.a enfermaria de Santa Casa em 1920.\\n\n",
       "729652              Antonio Austregésilo, o psiquiatra.\\n\n",
       "729653  As reações de Takata e formol-gel em face da p...\n",
       "729654                                            As reaç\n",
       "\n",
       "[729655 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos primeiro remover os acentos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(text):\n",
    "    '''Strip accents out.'''\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', text)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "clean2 = lambda x: cleaning1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df.lines.apply(remove_accents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A avifauna da regiao de Vila Bela da Santissim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Composicao de bandos mistos de aves em fragmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morcegos do Estado do Parana, Brasil (Mammalia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Riqueza da fauna de formigas (Hymenoptera: For...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lista de tipos de Dermaptera e Orthoptera (Ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729650</th>\n",
       "      <td>Antonio Austregesilo ou a grandeza e a dignida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729651</th>\n",
       "      <td>A 20.a enfermaria de Santa Casa em 1920.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729652</th>\n",
       "      <td>Antonio Austregesilo, o psiquiatra.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729653</th>\n",
       "      <td>As reacoes de Takata e formol-gel em face da p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729654</th>\n",
       "      <td>As reac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>729655 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    lines\n",
       "0       A avifauna da regiao de Vila Bela da Santissim...\n",
       "1       Composicao de bandos mistos de aves em fragmen...\n",
       "2       Morcegos do Estado do Parana, Brasil (Mammalia...\n",
       "3       Riqueza da fauna de formigas (Hymenoptera: For...\n",
       "4       Lista de tipos de Dermaptera e Orthoptera (Ins...\n",
       "...                                                   ...\n",
       "729650  Antonio Austregesilo ou a grandeza e a dignida...\n",
       "729651         A 20.a enfermaria de Santa Casa em 1920.\\n\n",
       "729652              Antonio Austregesilo, o psiquiatra.\\n\n",
       "729653  As reacoes de Takata e formol-gel em face da p...\n",
       "729654                                            As reac\n",
       "\n",
       "[729655 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos limpar, usando expressões regulares, tudo que não é caracter alfanumérico e passar tudo para caixa baixa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['lines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x000002B77A4794A0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brief_cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos lematizar e retirar as *stopwords*, para diminuir a dimensionalidade, com a biblioteca ```spacy```. Vamos usar ```spacy.pipe()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(doc):\n",
    "    # lematizar e retirar stopwords\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    # como Word2Vec usa palavras de contexto para aprender a representação vetorial de uma palavra-alvo,\n",
    "    # se uma frase tiver apenas uma ou duas palavras,\n",
    "    # o benefício para o treinamento é muito pequeno    \n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_process=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proteinas ryr ryr apresentar papar distinto mecanismo excitacao contracao diferencas mecanismo ativacao respostar ligante',\n",
       " '  rna total filar peitar pectoralis major m pse l h gt ph nao pse lt l h gt linhagem distinto cortar posturar utilizar estudar expressao genica gene ryr ryr pcr real',\n",
       " '  valorar medios expressao genica relativo rq inferior p lt frango pse linhagem comparar frango nao pse',\n",
       " '  outro nao haver diferencas p gt expressao independentemente linhagem estudar',\n",
       " '  resultar rq ryr indicar amostrar pse alteracao proporcao ryr ryr comumente encontrar musculos ave']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt[68162:68167]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt2 = [str(row.strip()) for row in txt if (row != None and row.strip() != '.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resultar mostrar melhor co solvente extracao tanino co supercritico aguar concentracao melhor solvente lavagem trap metanol',\n",
       " 'degradacao herbicida diuron estudar solo historico aplicacao obter aproximadamente degradacao solo historico aplicacao apo dia incubacao',\n",
       " 'haver aumentar numerar bacterias solo historico aplicacao x x ufc g solo',\n",
       " 'nao haver aumentar biomassa apo incubacao pôr encontrar significante residuo c diuron biomassa',\n",
       " 'consorciar tres bacterias isolar acinetobacter johnsonii especies bacillus sp conter diuron unica fonte carbono']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt2[63263:63268]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos remover os valores faltantes e duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avifauna regiao vila belo santissima trindade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>composicao bando misto ave fragmento matar atl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>morcego parana brasil mammalia chiroptera riqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>riqueza fauna formigo hymenoptera formicidae h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lista tipo dermaptera orthoptera insecta depos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729645</th>\n",
       "      <td>orientacao profissional importancia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729650</th>\n",
       "      <td>antonio austregesilo grandeza dignidade espiritar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729651</th>\n",
       "      <td>enfermar santo casar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729652</th>\n",
       "      <td>antonio austregesilo psiquiatro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729653</th>\n",
       "      <td>reacoes takata formol gel face protidemia tota...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>677319 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    clean\n",
       "0       avifauna regiao vila belo santissima trindade ...\n",
       "1       composicao bando misto ave fragmento matar atl...\n",
       "2       morcego parana brasil mammalia chiroptera riqu...\n",
       "3       riqueza fauna formigo hymenoptera formicidae h...\n",
       "4       lista tipo dermaptera orthoptera insecta depos...\n",
       "...                                                   ...\n",
       "729645                orientacao profissional importancia\n",
       "729650  antonio austregesilo grandeza dignidade espiritar\n",
       "729651                               enfermar santo casar\n",
       "729652                    antonio austregesilo psiquiatro\n",
       "729653  reacoes takata formol gel face protidemia tota...\n",
       "\n",
       "[677319 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'clean': txt})\n",
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "724700"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigramas\n",
    "O pacote ```Gensim Phrases``` detecta automaticamente frases comuns (bigramas) de uma lista de frases.\n",
    "\n",
    "Veja mais em: https://radimrehurek.com/gensim/models/phrases.html\n",
    "\n",
    "Com o método ```Phrases()```, vamos criar frases relevantes a partir da lista de frases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "sent = [row.split() for row in df_clean['clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Phraser()``` reduz o consumo de memória de ```phrases``` ao descartar estado do modelo não necessário para a detecção de bigramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos o corpus com base nos bigramas detectados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Palavras frequentes\n",
    "Vamos calcular a frequencia das palavras, para verificar a eficácia da lematização, remoção de palavras irrelevantes e adição de bigramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148119"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict \n",
    "\n",
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paciente',\n",
       " 'resultar',\n",
       " 'estudar',\n",
       " 'nao',\n",
       " 'apresentar',\n",
       " 'analisar',\n",
       " 'ser',\n",
       " 'realizar',\n",
       " 'utilizar',\n",
       " 'ano']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 3 - Treinamento do modelo\n",
    "\n",
    "Hora de treinar nosso modelo Word2Vec com nossos dados. Primeiro, vamos verificar o ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "from time import time\n",
    "\n",
    "cores = multiprocessing.cpu_count() # conta o número de núcleos do computador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos parametrizar nosso modelo.\n",
    "\n",
    "- *min_count*: Ignora todas as palavras com frequência absoluta total inferior a esta\n",
    "- *window*: A distância máxima entre a palavra atual e a prevista em uma frase. Por exemplo, palavras da janela à esquerda e palavras da janela à esquerda do nosso alvo\n",
    "- *size*: Dimensionalidade dos vetores\n",
    "- *sample*: O limite para configurar quais palavras de alta frequência são reduzidas aleatoriamente\n",
    "- *alpha*: A taxa de aprendizagem inicial\n",
    "- *min_alpha*: A taxa de aprendizado cairá linearmente para *min_alpha* conforme o treinamento progride\n",
    "- *negative*: Se > 0, a amostragem negativa será usada, o int para negativo especifica quantas \"palavras de ruído\" devem ser eliminadas. Se definido como 0, nenhuma amostra negativa é usada\n",
    "- *workers*: Quantidade de *threads* de trabalho para treinar o modelo (treinamento mais rápido com máquinas multicore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=2,\n",
    "                     vector_size=32,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=10,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construindo o vocabulário e treinando o modelo\n",
    "Parâmetros do treinamento:\n",
    "\n",
    "*total_examples: Contagem de sentenças;\n",
    "*epochs*: Número de iterações (épocas) no corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(sentences, progress_per=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158162476, 230529330)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 4 - Salvando o modelo\n",
    "Vamos salvar o modelo nos formatos *KeyedVectors* e binário, para utilizarmos posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-bc56ad85d6ac>:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)  # deixa o modelo mais eficiente, pois não vamos mais treiná-lo futuramente\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace=True)  # deixa o modelo mais eficiente, pois não vamos mais treiná-lo futuramente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"corpus_scielo.model\")\n",
    "w2v_model.wv.save_word2vec_format('corpus_scielo.bin', binary=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já treinamos nosso modelo, [vamos ver aqui como utilizá-lo](https://github.com/lisaterumi/word2vec-harry-potter-portugues/blob/main/%5B2%5D%20tSNE-Harry-Potter.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
